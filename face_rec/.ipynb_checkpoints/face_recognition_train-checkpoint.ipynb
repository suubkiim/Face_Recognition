{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8dea704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It trains face images using a simple CNN structure and exports a *.pb file.\n",
    "# The pb file can be used in OpenCV applications.\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import cv2\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "FLAGS = None\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "train_img_dir = 'train_images'\n",
    "categories = [name for name in os.listdir(train_img_dir) if os.path.isdir(os.path.join(train_img_dir, name))]\n",
    "categories.sort()\n",
    "\n",
    "extensions = ['png', 'jpg']  # lower case only\n",
    "\n",
    "# Parameters\n",
    "img_w = 150\n",
    "img_h = 200\n",
    "img_c = 1\n",
    "num_cls = len(categories)\n",
    "\n",
    "# Helper functions\n",
    "def create_image_list(image_dir):\n",
    "    '''Builds a list of training images from the file system.\n",
    "\n",
    "    Create image list in the image_dir directory.\n",
    "    The image_dir should contains two sub directories named non_repeat and repeat.\n",
    "    Using image files in these sub directories, a list will be created and returned.\n",
    "\n",
    "    Args:\n",
    "        image_dir: sub directory name\n",
    "\n",
    "    Returns:\n",
    "        The list elements contains a string and an integer.\n",
    "        The string contains the relative path for image file\n",
    "        and the integer must be 0(non_integer) or 1(repeat)\n",
    "    '''\n",
    "    if not os.path.exists(image_dir):\n",
    "        print('Error:', image_dir, 'is not exist!')\n",
    "        return None\n",
    "\n",
    "    image_list = []\n",
    "    for label, category in enumerate(categories):\n",
    "        filelist = os.listdir(os.path.join(image_dir, category))\n",
    "        for f in filelist:\n",
    "            dotext = os.path.splitext(f)[-1]\n",
    "            ext = dotext[1:]\n",
    "            if ext.lower() not in extensions:\n",
    "                continue\n",
    "\n",
    "            filepath = os.path.join(image_dir, category, f)\n",
    "            image_list.append([filepath, label])\n",
    "\n",
    "    return image_list\n",
    "\n",
    "\n",
    "def read_image(path):\n",
    "    '''Read an image in the path.\n",
    "\n",
    "    Args:\n",
    "        path: image file path\n",
    "\n",
    "    Returns:\n",
    "        The pixel value is normalized to be [0, 1].\n",
    "        The image size is (img_w x img_h).\n",
    "    '''\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) / 255.\n",
    "\n",
    "    if img.shape != (img_h, img_w):\n",
    "        img = cv2.resize(img, (img_w, img_h))\n",
    "\n",
    "    return img.reshape(img_h, img_w, img_c)\n",
    "\n",
    "\n",
    "def batch(paths, idx, batch_size):\n",
    "    '''Get a batch from image lists.\n",
    "\n",
    "    Args:\n",
    "        paths: image list\n",
    "        idx: index\n",
    "        batch_size: batch size\n",
    "\n",
    "    Returns:\n",
    "        Subset of image list starts from (idx * batch_size)\n",
    "    '''\n",
    "    num_imgs = len(paths)\n",
    "    idx1 = idx * batch_size\n",
    "    idx2 = (idx + 1) * batch_size\n",
    "    if idx2 > num_imgs:\n",
    "        idx2 = num_imgs\n",
    "    batch_list = paths[idx1: idx2]\n",
    "\n",
    "    imgs, labels = [], []\n",
    "    for i in range(batch_size):\n",
    "        imgs.append(read_image(batch_list[i][0]))\n",
    "        labels.append(batch_list[i][1])\n",
    "    return imgs, labels\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "\n",
    "    # Load images\n",
    "    train_list = create_image_list(train_img_dir)\n",
    "    if train_list is None:\n",
    "        return\n",
    "\n",
    "    print('Total number of train images:', len(train_list))\n",
    "\n",
    "    # Model configuration\n",
    "    tf.disable_eager_execution()\n",
    "\n",
    "    X = tf.placeholder(tf.float32, [None, img_h, img_w, img_c], name='data')\n",
    "    Y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "    conv1 = tf.layers.conv2d(X, 64, [3, 3], padding='same', activation=tf.nn.relu)\n",
    "    conv1_1 = tf.layers.conv2d(conv1, 64, [3, 3], padding='same', activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(conv1_1, [2, 2], strides=2)\n",
    "\n",
    "    conv2 = tf.layers.conv2d(pool1, 128, [3, 3], padding='same', activation=tf.nn.relu)\n",
    "    conv2_1 = tf.layers.conv2d(conv2, 128, [3, 3], padding='same', activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(conv2_1, [2, 2], strides=2)\n",
    "\n",
    "    conv3 = tf.layers.conv2d(pool2, 256, [3, 3], padding='same', activation=tf.nn.relu)\n",
    "    conv3_1 = tf.layers.conv2d(conv3, 256, [3, 3], padding='same', activation=tf.nn.relu)\n",
    "    pool3 = tf.layers.max_pooling2d(conv3, [2, 2], strides=2)\n",
    "\n",
    "    conv4 = tf.layers.conv2d(pool2, 12, [3, 3], activation=tf.nn.relu)\n",
    "    #pool3 = tf.layers.max_pooling2d(conv3, [2, 2], strides=2)\n",
    "\n",
    "    flat1 = tf.layers.flatten(conv4)\n",
    "    dense1 = tf.layers.dense(flat1, 512, activation=tf.nn.relu)\n",
    "    dense2 = tf.layers.dense(flat1, 512, activation=tf.nn.relu)\n",
    "\n",
    "    logits = tf.layers.dense(dense2, num_cls, activation=None)\n",
    "    final_tensor = tf.nn.softmax(logits, name='prob')\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "    optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(cost)\n",
    "\n",
    "    # Training\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        total_batch = int(len(train_list) / FLAGS.batch_size)\n",
    "        print('Total batch count:', total_batch)\n",
    "\n",
    "        print('Start learning!')\n",
    "        for epoch in range(FLAGS.num_epochs):\n",
    "\n",
    "            total_cost = 0\n",
    "            np.random.shuffle(train_list)\n",
    "\n",
    "            for i in range(total_batch):\n",
    "                imgs, labels = batch(train_list, i, FLAGS.batch_size)\n",
    "                _, cost_val = sess.run([optimizer, cost], feed_dict={X: imgs, Y: labels})\n",
    "                total_cost += cost_val\n",
    "\n",
    "            print('Epoch: %d, cost: %.8f' % ((epoch + 1), total_cost))\n",
    "\n",
    "            if (total_cost < FLAGS.minimum_cost):\n",
    "                print('Learning stoped because cost <', FLAGS.minimum_cost)\n",
    "                break\n",
    "\n",
    "        print('Learning finished!')\n",
    "\n",
    "        # Freeze variables and save pb file\n",
    "        output_graph_def = graph_util.convert_variables_to_constants(\n",
    "            sess, sess.graph_def, ['prob'])\n",
    "        with gfile.FastGFile(FLAGS.output_model, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "\n",
    "    input('Press Enter to continue...')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39865c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of train images: 1713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\subinkim\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\convolutional.py:414: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
      "c:\\users\\subinkim\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "c:\\users\\subinkim\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\pooling.py:310: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
      "  warnings.warn('`tf.layers.max_pooling2d` is deprecated and '\n",
      "c:\\users\\subinkim\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "c:\\users\\subinkim\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batch count: 57\n",
      "Start learning!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1017709239ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munparsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0munparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\subinkim\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m   \u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\subinkim\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\absl\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv, flags_parser)\u001b[0m\n\u001b[0;32m    301\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m       \u001b[0m_run_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m       \u001b[0musage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\subinkim\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\absl\\app.py\u001b[0m in \u001b[0;36m_run_main\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e57c4b479cd6>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(argv)\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m                 \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m                 \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m                 \u001b[0mtotal_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcost_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\subinkim\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    968\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\subinkim\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1192\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\subinkim\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1369\u001b[0m                            run_metadata)\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\subinkim\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1373\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\subinkim\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1360\u001b[0m                                       target_list, run_metadata)\n\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\subinkim\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1449\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[0;32m   1450\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1451\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m                                             run_metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--num_epochs',\n",
    "    type=int,\n",
    "    default=200,\n",
    "    help='Number of epochs to run trainer.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--learning_rate',\n",
    "    type=float,\n",
    "    default=0.0001,\n",
    "    help='How large a learning rate to use when training.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--batch_size',\n",
    "    type=int,\n",
    "    default=30,\n",
    "    help='How many images to train on at a time.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--minimum_cost',\n",
    "    type=float,\n",
    "    default=0.000001,\n",
    "    help='Minimum cost to stop learning.'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--output_model',\n",
    "    type=str,\n",
    "    default='./face_rec.pb',\n",
    "    help='Output model file name.'\n",
    ")\n",
    "FLAGS, unparsed = parser.parse_known_args(args=[])\n",
    "\n",
    "tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ceeee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
